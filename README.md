# AI Orchestrator v6.2

Un orchestrateur IA autonome avec pipeline Workflow complet, exÃ©cution d'outils sÃ©curisÃ©e, et interface Orchestrator UI professionnelle.

## ğŸ¯ FonctionnalitÃ©s

- **Pipeline Workflow** : SPEC â†’ PLAN â†’ EXECUTE â†’ VERIFY â†’ REPAIR â†’ COMPLETE
- **17 outils** intÃ©grÃ©s (systÃ¨me, fichiers, QA, utilitaires, rÃ©seau)
- **7 outils QA** : git_status, git_diff, run_tests, run_lint, run_format, run_build, run_typecheck
- **Erreurs rÃ©cupÃ©rables** : auto-correction via search_directory/search_files
- **Streaming WebSocket** temps rÃ©el avec run_id et phases
- **Run Inspector** : stepper workflow, tabs Tools/QA/Raw, verdict PASS/FAIL
- **SÃ©curitÃ©** : allowlist commandes, sandbox Docker, workspace isolÃ©
- **Multi-modÃ¨les** : Ollama local + proxies cloud

## ğŸ—ï¸ Architecture

```
ai-orchestrator/
â”œâ”€â”€ backend/                 # FastAPI + ReAct Engine
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ api/v1/         # Endpoints REST + WebSocket
â”‚   â”‚   â”œâ”€â”€ core/           # Config, database, security
â”‚   â”‚   â”œâ”€â”€ models/         # Pydantic schemas
â”‚   â”‚   â””â”€â”€ services/       # ToolExecutor, ReActEngine, LLM
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ frontend/               # Vue 3 + Tailwind
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/     # Chat, RunInspector, StatusBar
â”‚   â”‚   â”œâ”€â”€ views/          # ChatView, ToolsView, Settings
â”‚   â”‚   â”œâ”€â”€ stores/         # Pinia (auth, chat, tools, system)
â”‚   â”‚   â””â”€â”€ services/       # API client, WebSocket
â”‚   â””â”€â”€ package.json
â”‚
â””â”€â”€ docs/                   # Documentation
```

## ğŸš€ Installation

### Backend

```bash
cd backend
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt
cp .env.example .env
# Ã‰diter .env avec vos valeurs
uvicorn main:app --host 0.0.0.0 --port 8001
```

### Frontend

```bash
cd frontend
npm install
npm run dev      # DÃ©veloppement
npm run build    # Production
```

## ğŸ”§ Configuration

Copier `backend/.env.example` vers `backend/.env` et configurer :

| Variable | Description | DÃ©faut |
|----------|-------------|--------|
| `DATABASE_URL` | SQLite ou PostgreSQL | `sqlite:///./data/orchestrator.db` |
| `JWT_SECRET` | ClÃ© secrÃ¨te JWT | (Ã  dÃ©finir) |
| `OLLAMA_URL` | URL Ollama | `http://localhost:11434` |
| `DEFAULT_MODEL` | ModÃ¨le par dÃ©faut | `kimi-k2:1t-cloud` |
| `MAX_ITERATIONS` | Max boucles ReAct | `10` |

## ğŸ“¡ API Endpoints

| Endpoint | Description |
|----------|-------------|
| `POST /api/v1/auth/login` | Authentification |
| `GET /api/v1/conversations` | Liste conversations |
| `WS /api/v1/chat/ws` | Chat streaming |
| `GET /api/v1/tools` | Liste outils |
| `GET /api/v1/system/health` | Ã‰tat systÃ¨me |
| `GET /api/v1/system/models` | ModÃ¨les disponibles |

## ğŸ¨ Interface

- **Cockpit 3 panneaux** : Conversations / Chat / Run Inspector
- **Run Inspector** : Visualisation temps rÃ©el thinking â†’ tool â†’ complete
- **SÃ©lecteur modÃ¨le** : Switch entre modÃ¨les Ollama
- **Export** : JSON / Markdown

## ğŸ“ License

MIT License - Lalpha 2025
