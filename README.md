# AI Orchestrator v6.1

Un orchestrateur IA autonome avec boucle ReAct, exÃ©cution d'outils sÃ©curisÃ©e, et interface cockpit professionnelle.

## ğŸ¯ FonctionnalitÃ©s

- **Boucle ReAct** : Reason â†’ Act â†’ Observe â†’ Repeat
- **72+ outils** intÃ©grÃ©s (systÃ¨me, Docker, rÃ©seau, fichiers, etc.)
- **Streaming WebSocket** temps rÃ©el
- **Run Inspector** : traÃ§abilitÃ© complÃ¨te des exÃ©cutions
- **SÃ©curitÃ©** : allowlist de 175 commandes, JWT auth, rate limiting
- **Multi-modÃ¨les** : Ollama local + proxies cloud

## ğŸ—ï¸ Architecture

```
ai-orchestrator/
â”œâ”€â”€ backend/                 # FastAPI + ReAct Engine
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ api/v1/         # Endpoints REST + WebSocket
â”‚   â”‚   â”œâ”€â”€ core/           # Config, database, security
â”‚   â”‚   â”œâ”€â”€ models/         # Pydantic schemas
â”‚   â”‚   â””â”€â”€ services/       # ToolExecutor, ReActEngine, LLM
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ frontend/               # Vue 3 + Tailwind
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/     # Chat, RunInspector, StatusBar
â”‚   â”‚   â”œâ”€â”€ views/          # ChatView, ToolsView, Settings
â”‚   â”‚   â”œâ”€â”€ stores/         # Pinia (auth, chat, tools, system)
â”‚   â”‚   â””â”€â”€ services/       # API client, WebSocket
â”‚   â””â”€â”€ package.json
â”‚
â””â”€â”€ docs/                   # Documentation
```

## ğŸš€ Installation

### Backend

```bash
cd backend
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt
cp .env.example .env
# Ã‰diter .env avec vos valeurs
uvicorn main:app --host 0.0.0.0 --port 8001
```

### Frontend

```bash
cd frontend
npm install
npm run dev      # DÃ©veloppement
npm run build    # Production
```

## ğŸ”§ Configuration

Copier `backend/.env.example` vers `backend/.env` et configurer :

| Variable | Description | DÃ©faut |
|----------|-------------|--------|
| `DATABASE_URL` | SQLite ou PostgreSQL | `sqlite:///./data/orchestrator.db` |
| `JWT_SECRET` | ClÃ© secrÃ¨te JWT | (Ã  dÃ©finir) |
| `OLLAMA_URL` | URL Ollama | `http://localhost:11434` |
| `DEFAULT_MODEL` | ModÃ¨le par dÃ©faut | `kimi-k2:1t-cloud` |
| `MAX_ITERATIONS` | Max boucles ReAct | `10` |

## ğŸ“¡ API Endpoints

| Endpoint | Description |
|----------|-------------|
| `POST /api/v1/auth/login` | Authentification |
| `GET /api/v1/conversations` | Liste conversations |
| `WS /api/v1/chat/ws` | Chat streaming |
| `GET /api/v1/tools` | Liste outils |
| `GET /api/v1/system/health` | Ã‰tat systÃ¨me |
| `GET /api/v1/system/models` | ModÃ¨les disponibles |

## ğŸ¨ Interface

- **Cockpit 3 panneaux** : Conversations / Chat / Run Inspector
- **Run Inspector** : Visualisation temps rÃ©el thinking â†’ tool â†’ complete
- **SÃ©lecteur modÃ¨le** : Switch entre modÃ¨les Ollama
- **Export** : JSON / Markdown

## ğŸ“ License

MIT License - Lalpha 2025
