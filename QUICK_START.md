# Quick Start - AI Orchestrator v7.0

Guide de d√©marrage rapide pour l'AI Orchestrator v7.0.

---

## ‚ö° D√©marrage Rapide (< 5 minutes)

### Pr√©requis
```bash
# V√©rifier les pr√©requis
python3 --version  # 3.11+
ollama --version   # Ollama install√©
ollama list        # Au moins 1 mod√®le disponible
```

### Installation Backend

```bash
cd /home/lalpha/projets/ai-tools/ai-orchestrator

# Activer l'environnement virtuel
source .venv/bin/activate
# ou si pas encore cr√©√©:
python3 -m venv .venv && source .venv/bin/activate

# Installer les d√©pendances
pip install -r backend/requirements.txt

# Configurer (optionnel - les d√©fauts fonctionnent)
cp backend/.env.example backend/.env
# √âditer backend/.env si n√©cessaire

# Lancer le backend
python backend/main.py
```

Le backend d√©marre sur **http://localhost:8001**

### Tests Rapides

```bash
# Dans un autre terminal
curl http://localhost:8001/api/v1/system/health

# Ou avec Python
python -c "import requests; print(requests.get('http://localhost:8001/api/v1/system/health').json())"
```

### Installation Frontend

```bash
cd frontend

# Installer les d√©pendances (premi√®re fois seulement)
npm install

# Lancer en dev
npm run dev
```

Le frontend d√©marre sur **http://localhost:3000** (ou 3001 si 3000 occup√©)

---

## üß™ Tester l'Orchestrator

### Via l'Interface Web

1. Ouvrir http://localhost:3000
2. Cliquer "Nouvelle conversation"
3. Essayer:
   - **Conversationnel:** "bonjour"
   - **Question simple:** "quelle heure est-il?"
   - **Question syst√®me:** "uptime du serveur?"
   - **Avec recherche:** "liste les fichiers dans /var/log"

### Via l'API

```bash
# Message conversationnel
curl -X POST http://localhost:8001/api/v1/chat \
  -H "Content-Type: application/json" \
  -d '{"message":"bonjour", "model":"kimi-k2:1t-cloud"}'

# Question avec outil
curl -X POST http://localhost:8001/api/v1/chat \
  -H "Content-Type: application/json" \
  -d '{"message":"quelle heure est-il?", "model":"kimi-k2:1t-cloud"}'

# Voir les mod√®les disponibles
curl http://localhost:8001/api/v1/system/models

# Voir les outils disponibles
curl http://localhost:8001/api/v1/tools
```

---

## üîç V√©rifier que Tout Fonctionne

### Backend
```bash
# Tests unitaires
python -m pytest backend/tests -v

# Sant√© de l'API
curl http://localhost:8001/api/v1/system/health
# Devrait retourner: {"status":"healthy","version":"7.0"}

# Connexion Ollama
curl http://localhost:8001/api/v1/system/stats
# Devrait montrer "ollama_status":"connected"
```

### Frontend
- Ouvrir http://localhost:3000
- V√©rifier que "Op√©rationnel" est affich√© en vert
- Tester l'envoi d'un message
- V√©rifier que le Run Inspector s'affiche

---

## üõ†Ô∏è Configuration Avanc√©e

### Changer le Mod√®le LLM

```bash
# backend/.env
DEFAULT_MODEL=qwen2.5-coder:32b-instruct-q4_K_M
EXECUTOR_MODEL=qwen2.5-coder:32b-instruct-q4_K_M
```

### Activer la V√©rification QA

```bash
# backend/.env
VERIFY_REQUIRED=true
MAX_REPAIR_CYCLES=2
```

### Mode Sandbox Docker

```bash
# backend/.env
EXECUTE_MODE=sandbox
SANDBOX_IMAGE=ubuntu:24.04
SANDBOX_MEMORY=512m
```

---

## üìä Monitoring

### Logs Backend
```bash
# En dev
tail -f backend.log

# Avec systemd
journalctl -u ai-orchestrator -f
```

### M√©triques Prometheus
```bash
curl http://localhost:8001/metrics
```

### Logs Frontend
```bash
# Console navigateur (F12)
# ou
docker logs -f ai-orchestrator-frontend
```

---

## üö® D√©pannage

### Backend ne d√©marre pas

**Probl√®me:** Port 8001 d√©j√† utilis√©
```bash
# Trouver le processus
lsof -i :8001
# Ou changer le port
# backend/.env
PORT=8002
```

**Probl√®me:** Ollama non connect√©
```bash
# V√©rifier Ollama
systemctl status ollama
# D√©marrer si n√©cessaire
systemctl start ollama
```

### Frontend ne se connecte pas

**Probl√®me:** CORS
```bash
# V√©rifier backend/.env
CORS_ORIGINS=["http://localhost:3000"]
```

**Probl√®me:** URL backend incorrecte
```bash
# frontend/.env ou frontend/src/services/api.js
VITE_API_URL=http://localhost:8001
```

### R√©ponses lentes ou absentes

Voir [docs/TROUBLESHOOTING.md](docs/TROUBLESHOOTING.md) section "Aucune r√©ponse ou r√©ponses lentes (v7.0)"

**Quick fix:**
- Questions doivent contenir "?" ou mots interrogatifs
- √âviter commandes ambigu√´s sans contexte

---

## üìö Documentation

| Document | Description |
|----------|-------------|
| [README.md](README.md) | Vue d'ensemble |
| [ARCHITECTURE.md](docs/ARCHITECTURE.md) | Architecture d√©taill√©e |
| [API.md](docs/API.md) | Documentation API |
| [TROUBLESHOOTING.md](docs/TROUBLESHOOTING.md) | R√©solution probl√®mes |
| [SECURITY.md](docs/SECURITY.md) | S√©curit√© et isolation |
| [TEST_REPORT_2026-01-21.md](TEST_REPORT_2026-01-21.md) | Rapport de tests |

---

## üéØ Prochaines √âtapes

1. **Explorer l'UI:** Tester diff√©rentes requ√™tes
2. **Voir le Run Inspector:** Observer les phases du workflow
3. **Tester les outils:** Essayer les 72 outils disponibles
4. **Configurer les mod√®les:** Ajouter d'autres mod√®les LLM
5. **Lire la doc:** Approfondir avec [docs/](docs/)

---

## üí° Exemples de Requ√™tes

### Questions Simples (Fast Path)
```
- "bonjour"
- "quelle heure est-il?"
- "uptime du serveur?"
- "quels mod√®les sont disponibles?"
- "liste les outils"
```

### Actions (Full Workflow)
```
- "cr√©e un fichier test.txt avec 'hello world'"
- "liste les fichiers Python dans le projet"
- "analyse les logs du serveur"
- "v√©rifie le code avec ruff"
```

### Avec V√©rification QA
```
- "√©cris un test unitaire pour calculate()"
- "formate le code Python"
- "ex√©cute les tests pytest"
```

---

## üÜò Support

- **Issues:** https://github.com/lalphadb/ai-orchestrator/issues
- **Docs:** [docs/INDEX.md](docs/INDEX.md)
- **Tests:** Voir [TEST_REPORT_2026-01-21.md](TEST_REPORT_2026-01-21.md)

---

**Version:** 7.0  
**Date:** 2026-01-21  
**Status:** ‚úÖ Production Ready
