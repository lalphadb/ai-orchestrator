"""
LearningMemory - M√©moire d'apprentissage bas√©e sur ChromaDB

Stocke et r√©cup√®re les exp√©riences pour am√©liorer les r√©ponses:
- Commandes r√©ussies avec leur contexte
- Erreurs et leurs corrections
- Patterns de r√©solution de probl√®mes
- Pr√©f√©rences utilisateur
"""

import hashlib
import json
import logging
import os
from datetime import datetime
from typing import Any, Dict, List, Optional

import chromadb
from chromadb.config import Settings
from tenacity import (retry, retry_if_exception_type, stop_after_attempt,
                      wait_exponential)

logger = logging.getLogger(__name__)


class LearningMemory:
    """M√©moire d'apprentissage persistante avec ChromaDB."""

    def __init__(self, chroma_host: str = "localhost", chroma_port: int = 8000):
        """
        Initialise la connexion √† ChromaDB avec retry automatique.

        Args:
            chroma_host: H√¥te ChromaDB
            chroma_port: Port ChromaDB
        """
        self.chroma_host = chroma_host
        self.chroma_port = chroma_port
        self.client = None
        self.experiences = None
        self.patterns = None
        self.corrections = None
        self.user_context = None

        # Tenter connexion avec retry
        try:
            self._connect_with_retry()
        except Exception as e:
            logger.error(f"Impossible de se connecter √† ChromaDB apr√®s plusieurs tentatives: {e}")
            self.client = None

    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=2, max=10),
        retry=retry_if_exception_type((ConnectionError, Exception)),
        reraise=True,
    )
    def _connect_with_retry(self):
        """Connexion ChromaDB avec retry automatique (3 tentatives avec backoff exponentiel)."""
        logger.info(f"Tentative de connexion √† ChromaDB {self.chroma_host}:{self.chroma_port}...")

        self.client = chromadb.HttpClient(
            host=self.chroma_host,
            port=self.chroma_port,
            settings=Settings(anonymized_telemetry=False),
        )

        # Initialiser les collections
        self._init_collections()

        logger.info(f"‚úÖ LearningMemory connect√© √† ChromaDB {self.chroma_host}:{self.chroma_port}")

    def reconnect(self):
        """Force la reconnexion √† ChromaDB (en cas de perte de connexion)."""
        logger.info("üîÑ Reconnexion forc√©e √† ChromaDB...")
        self.client = None
        try:
            self._connect_with_retry()
            return True
        except Exception as e:
            logger.error(f"‚ùå √âchec de reconnexion √† ChromaDB: {e}")
            return False

    def _init_collections(self):
        """Initialise les collections ChromaDB."""
        # Collection des exp√©riences (succ√®s/√©checs)
        self.experiences = self.client.get_or_create_collection(
            name="ai_experiences",
            metadata={"description": "Exp√©riences d'ex√©cution (succ√®s/√©checs)"},
        )

        # Collection des patterns de r√©solution
        self.patterns = self.client.get_or_create_collection(
            name="ai_patterns", metadata={"description": "Patterns de r√©solution de probl√®mes"}
        )

        # Collection des corrections d'erreurs
        self.corrections = self.client.get_or_create_collection(
            name="ai_corrections", metadata={"description": "Erreurs et leurs corrections"}
        )

        # Collection des pr√©f√©rences/contexte utilisateur
        self.user_context = self.client.get_or_create_collection(
            name="ai_user_context", metadata={"description": "Contexte et pr√©f√©rences utilisateur"}
        )

        logger.info("Collections ChromaDB initialis√©es")

    def _generate_id(self, content: str) -> str:
        """G√©n√®re un ID unique bas√© sur le contenu."""
        return hashlib.md5(content.encode()).hexdigest()[:16]

    # ==================== EXP√âRIENCES ====================

    def store_experience(
        self,
        query: str,
        response: str,
        tools_used: List[str],
        success: bool,
        duration_ms: int,
        iterations: int,
        error: Optional[str] = None,
        user_id: Optional[str] = None,
    ) -> str:
        """
        Stocke une exp√©rience d'ex√©cution.

        Args:
            query: Question/demande originale
            response: R√©ponse g√©n√©r√©e
            tools_used: Liste des outils utilis√©s
            success: Si l'ex√©cution a r√©ussi
            duration_ms: Dur√©e en millisecondes
            iterations: Nombre d'it√©rations ReAct
            error: Message d'erreur si √©chec
            user_id: ID utilisateur optionnel

        Returns:
            ID de l'exp√©rience stock√©e
        """
        if not self.client:
            return None

        exp_id = self._generate_id(f"{query}{datetime.now().isoformat()}")

        # Document texte pour la recherche s√©mantique
        document = f"Query: {query}\nTools: {', '.join(tools_used)}\nSuccess: {success}"
        if error:
            document += f"\nError: {error}"

        # M√©tadonn√©es structur√©es
        metadata = {
            "query": query[:500],  # Limite pour ChromaDB
            "success": success,
            "tools_used": json.dumps(tools_used),
            "duration_ms": duration_ms,
            "iterations": iterations,
            "timestamp": datetime.now().isoformat(),
            "user_id": user_id or "anonymous",
            "score": 1.0 if success else 0.0,  # Score initial
        }

        if error:
            metadata["error"] = error[:500]

        try:
            self.experiences.add(ids=[exp_id], documents=[document], metadatas=[metadata])
            logger.info(f"Exp√©rience stock√©e: {exp_id} (success={success})")
            return exp_id
        except Exception as e:
            logger.error(f"Erreur stockage exp√©rience: {e}")
            return None

    def get_similar_experiences(
        self, query: str, n_results: int = 5, success_only: bool = True
    ) -> List[Dict[str, Any]]:
        """
        R√©cup√®re les exp√©riences similaires pour enrichir le contexte.

        Args:
            query: Question actuelle
            n_results: Nombre de r√©sultats
            success_only: Ne retourner que les succ√®s

        Returns:
            Liste des exp√©riences similaires avec leur score
        """
        if not self.client:
            return []

        try:
            # Recherche s√©mantique
            where_filter = {"success": True} if success_only else None

            results = self.experiences.query(
                query_texts=[query], n_results=n_results, where=where_filter
            )

            experiences = []
            if results and results["metadatas"]:
                for i, metadata in enumerate(results["metadatas"][0]):
                    exp = {
                        "id": results["ids"][0][i],
                        "query": metadata.get("query", ""),
                        "tools_used": json.loads(metadata.get("tools_used", "[]")),
                        "success": metadata.get("success", False),
                        "score": metadata.get("score", 0.0),
                        "distance": results["distances"][0][i] if results["distances"] else 0,
                        "relevance": 1
                        - (results["distances"][0][i] if results["distances"] else 0),
                    }
                    experiences.append(exp)

            return experiences

        except Exception as e:
            logger.error(f"Erreur recherche exp√©riences: {e}")
            return []

    # ==================== PATTERNS ====================

    def store_pattern(
        self,
        problem_type: str,
        solution_steps: List[str],
        tools_sequence: List[str],
        success_rate: float,
        examples: List[str],
    ) -> str:
        """
        Stocke un pattern de r√©solution r√©ussi.

        Args:
            problem_type: Type de probl√®me (ex: "docker_debug", "file_search")
            solution_steps: √âtapes de r√©solution
            tools_sequence: S√©quence d'outils utilis√©s
            success_rate: Taux de succ√®s du pattern
            examples: Exemples de requ√™tes r√©solues

        Returns:
            ID du pattern
        """
        if not self.client:
            return None

        pattern_id = self._generate_id(f"{problem_type}{json.dumps(tools_sequence)}")

        document = f"Problem: {problem_type}\nSteps: {'; '.join(solution_steps)}\nTools: {', '.join(tools_sequence)}"

        metadata = {
            "problem_type": problem_type,
            "solution_steps": json.dumps(solution_steps),
            "tools_sequence": json.dumps(tools_sequence),
            "success_rate": success_rate,
            "examples": json.dumps(examples[:5]),  # Max 5 exemples
            "usage_count": 1,
            "last_used": datetime.now().isoformat(),
        }

        try:
            # V√©rifier si le pattern existe d√©j√†
            existing = self.patterns.get(ids=[pattern_id])
            if existing and existing["ids"]:
                # Mettre √† jour le compteur
                old_meta = existing["metadatas"][0]
                metadata["usage_count"] = old_meta.get("usage_count", 0) + 1
                self.patterns.update(ids=[pattern_id], metadatas=[metadata])
            else:
                self.patterns.add(ids=[pattern_id], documents=[document], metadatas=[metadata])

            logger.info(f"Pattern stock√©/mis √† jour: {problem_type}")
            return pattern_id

        except Exception as e:
            logger.error(f"Erreur stockage pattern: {e}")
            return None

    def get_relevant_patterns(self, query: str, n_results: int = 3) -> List[Dict[str, Any]]:
        """
        R√©cup√®re les patterns pertinents pour la requ√™te.

        Args:
            query: Question actuelle
            n_results: Nombre de r√©sultats

        Returns:
            Liste des patterns avec leurs m√©tadonn√©es
        """
        if not self.client:
            return []

        try:
            results = self.patterns.query(query_texts=[query], n_results=n_results)

            patterns = []
            if results and results["metadatas"]:
                for i, metadata in enumerate(results["metadatas"][0]):
                    pattern = {
                        "problem_type": metadata.get("problem_type", ""),
                        "solution_steps": json.loads(metadata.get("solution_steps", "[]")),
                        "tools_sequence": json.loads(metadata.get("tools_sequence", "[]")),
                        "success_rate": metadata.get("success_rate", 0.0),
                        "usage_count": metadata.get("usage_count", 0),
                        "relevance": 1
                        - (results["distances"][0][i] if results["distances"] else 0),
                    }
                    patterns.append(pattern)

            return patterns

        except Exception as e:
            logger.error(f"Erreur recherche patterns: {e}")
            return []

    def get_top_patterns(self, limit: int = 10) -> List[Dict[str, Any]]:
        """
        R√©cup√®re les patterns les plus utilis√©s.

        Args:
            limit: Nombre maximum de patterns √† retourner

        Returns:
            Liste des patterns tri√©s par usage_count descendant
        """
        if not self.client:
            return []

        try:
            # R√©cup√©rer tous les patterns
            results = self.patterns.get(include=["metadatas", "documents"])

            if not results or not results["metadatas"]:
                return []

            # Convertir en liste de dicts avec usage_count
            patterns = []
            for i, metadata in enumerate(results["metadatas"]):
                pattern = {
                    "pattern": results["documents"][i],
                    "problem_type": metadata.get("problem_type", ""),
                    "solution_steps": json.loads(metadata.get("solution_steps", "[]")),
                    "tools_sequence": json.loads(metadata.get("tools_sequence", "[]")),
                    "success_rate": metadata.get("success_rate", 0.0),
                    "usage_count": metadata.get("usage_count", 0),
                    "created_at": metadata.get("created_at", ""),
                }
                patterns.append(pattern)

            # Trier par usage_count descendant
            patterns.sort(key=lambda x: x["usage_count"], reverse=True)

            return patterns[:limit]

        except Exception as e:
            logger.error(f"Erreur get_top_patterns: {e}")
            return []

    # ==================== CORRECTIONS ====================

    def store_correction(
        self,
        error_type: str,
        error_message: str,
        failed_approach: str,
        successful_correction: str,
        context: str,
    ) -> str:
        """
        Stocke une correction d'erreur pour apprentissage.

        Args:
            error_type: Type d'erreur (ex: "command_not_found", "permission_denied")
            error_message: Message d'erreur original
            failed_approach: Approche qui a √©chou√©
            successful_correction: Correction qui a fonctionn√©
            context: Contexte de l'erreur

        Returns:
            ID de la correction
        """
        if not self.client:
            return None

        corr_id = self._generate_id(f"{error_type}{error_message[:100]}")

        document = f"Error: {error_type}\nMessage: {error_message}\nFailed: {failed_approach}\nCorrection: {successful_correction}"

        metadata = {
            "error_type": error_type,
            "error_message": error_message[:500],
            "failed_approach": failed_approach[:500],
            "successful_correction": successful_correction[:1000],
            "context": context[:500],
            "timestamp": datetime.now().isoformat(),
            "times_used": 1,
        }

        try:
            self.corrections.add(ids=[corr_id], documents=[document], metadatas=[metadata])
            logger.info(f"Correction stock√©e: {error_type}")
            return corr_id
        except Exception as e:
            logger.error(f"Erreur stockage correction: {e}")
            return None

    def get_correction_for_error(
        self, error_message: str, context: str = ""
    ) -> Optional[Dict[str, Any]]:
        """
        Trouve une correction pour une erreur similaire.

        Args:
            error_message: Message d'erreur
            context: Contexte optionnel

        Returns:
            Correction trouv√©e ou None
        """
        if not self.client:
            return None

        try:
            query = f"{error_message} {context}"
            results = self.corrections.query(query_texts=[query], n_results=1)

            if results and results["metadatas"] and results["metadatas"][0]:
                metadata = results["metadatas"][0][0]
                distance = results["distances"][0][0] if results["distances"] else 1

                # Seulement si la correspondance est bonne (distance < 0.5)
                if distance < 0.5:
                    return {
                        "error_type": metadata.get("error_type", ""),
                        "successful_correction": metadata.get("successful_correction", ""),
                        "context": metadata.get("context", ""),
                        "relevance": 1 - distance,
                    }

            return None

        except Exception as e:
            logger.error(f"Erreur recherche correction: {e}")
            return None

    # ==================== CONTEXTE UTILISATEUR ====================

    def store_user_preference(
        self, user_id: str, preference_type: str, preference_value: str, context: str = ""
    ):
        """Stocke une pr√©f√©rence utilisateur."""
        if not self.client:
            return

        pref_id = self._generate_id(f"{user_id}{preference_type}")

        document = f"User preference: {preference_type} = {preference_value}"

        metadata = {
            "user_id": user_id,
            "preference_type": preference_type,
            "preference_value": preference_value,
            "context": context,
            "updated_at": datetime.now().isoformat(),
        }

        try:
            # Upsert
            existing = self.user_context.get(ids=[pref_id])
            if existing and existing["ids"]:
                self.user_context.update(ids=[pref_id], documents=[document], metadatas=[metadata])
            else:
                self.user_context.add(ids=[pref_id], documents=[document], metadatas=[metadata])
        except Exception as e:
            logger.error(f"Erreur stockage pr√©f√©rence: {e}")

    def get_user_context(self, user_id: str) -> Dict[str, Any]:
        """R√©cup√®re le contexte utilisateur."""
        if not self.client:
            return {}

        try:
            results = self.user_context.get(where={"user_id": user_id})

            context = {}
            if results and results["metadatas"]:
                for metadata in results["metadatas"]:
                    pref_type = metadata.get("preference_type", "")
                    pref_value = metadata.get("preference_value", "")
                    if pref_type:
                        context[pref_type] = pref_value

            return context

        except Exception as e:
            logger.error(f"Erreur r√©cup√©ration contexte: {e}")
            return {}

    # ==================== STATS ====================

    def get_stats(self) -> Dict[str, Any]:
        """Retourne les statistiques de la m√©moire."""
        if not self.client:
            return {"status": "disconnected"}

        try:
            return {
                "status": "connected",
                "experiences_count": self.experiences.count(),
                "patterns_count": self.patterns.count(),
                "corrections_count": self.corrections.count(),
                "user_contexts_count": self.user_context.count(),
            }
        except Exception as e:
            return {"status": "error", "error": str(e)}

    def update_experience_score(self, exp_id: str, score_delta: float):
        """Met √† jour le score d'une exp√©rience (feedback)."""
        if not self.client:
            return

        try:
            existing = self.experiences.get(ids=[exp_id])
            if existing and existing["metadatas"]:
                metadata = existing["metadatas"][0]
                new_score = max(0, min(1, metadata.get("score", 0.5) + score_delta))
                metadata["score"] = new_score
                self.experiences.update(ids=[exp_id], metadatas=[metadata])
                logger.info(f"Score mis √† jour: {exp_id} -> {new_score}")
        except Exception as e:
            logger.error(f"Erreur mise √† jour score: {e}")


# Instance singleton
_learning_memory: Optional[LearningMemory] = None


def get_learning_memory() -> LearningMemory:
    """Retourne l'instance singleton de LearningMemory."""
    global _learning_memory
    if _learning_memory is None:
        chroma_host = os.getenv("CHROMA_HOST", "localhost")
        chroma_port = int(os.getenv("CHROMA_PORT", "8000"))
        _learning_memory = LearningMemory(chroma_host=chroma_host, chroma_port=chroma_port)
    return _learning_memory
