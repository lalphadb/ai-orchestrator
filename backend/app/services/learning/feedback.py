"""
FeedbackCollector - Collecte et traitement du feedback utilisateur

GÃ¨re:
- Feedback positif/nÃ©gatif sur les rÃ©ponses
- Persistence en base de donnÃ©es SQLite
- Analyse des tendances
- Mise Ã  jour des scores d'apprentissage
- Export des donnÃ©es pour fine-tuning
"""

import json
import logging
from dataclasses import dataclass
from datetime import datetime, timedelta, timezone
from enum import Enum
from typing import Any, Dict, List, Optional

from app.core.database import Feedback as FeedbackModel
from app.core.database import get_db_session
from sqlalchemy.orm import Session

logger = logging.getLogger(__name__)


class FeedbackType(str, Enum):
    """Types de feedback."""

    POSITIVE = "positive"  # ðŸ‘
    NEGATIVE = "negative"  # ðŸ‘Ž
    CORRECTION = "correction"  # Correction fournie par l'utilisateur


@dataclass
class Feedback:
    """Structure d'un feedback (pour compatibilitÃ© API)."""

    message_id: str
    conversation_id: str
    feedback_type: FeedbackType
    timestamp: str
    query: str
    response: str
    tools_used: Optional[List[str]] = None
    corrected_response: Optional[str] = None
    reason: Optional[str] = None


class FeedbackCollector:
    """Collecteur et analyseur de feedback avec persistence DB."""

    def __init__(self):
        """Initialise le collecteur."""
        pass

    def add_feedback(
        self,
        db: Session,
        message_id: int,
        conversation_id: str,
        user_id: str,
        feedback_type: FeedbackType,
        query: str,
        response: str,
        tools_used: List[Dict[str, Any]],
        corrected_response: Optional[str] = None,
        reason: Optional[str] = None,
    ) -> Feedback:
        """
        Enregistre un feedback en base de donnÃ©es.

        Args:
            db: Session base de donnÃ©es
            message_id: ID du message Ã©valuÃ©
            conversation_id: ID de la conversation
            user_id: ID de l'utilisateur
            feedback_type: Type de feedback
            query: Question originale
            response: RÃ©ponse Ã©valuÃ©e
            tools_used: Outils utilisÃ©s
            corrected_response: Correction fournie (optionnel)
            reason: Raison du feedback nÃ©gatif (optionnel)

        Returns:
            Feedback enregistrÃ©
        """
        # CrÃ©er feedback DB
        feedback_db = FeedbackModel(
            message_id=message_id,
            conversation_id=conversation_id,
            user_id=user_id,
            feedback_type=feedback_type.value,
            query=query,
            response=response,
            corrected_response=corrected_response,
            tools_used=json.dumps(tools_used) if tools_used else None,
            reason=reason,
        )

        db.add(feedback_db)
        db.commit()
        db.refresh(feedback_db)

        logger.info(f"Feedback {feedback_type.value} enregistrÃ© pour message {message_id}")

        # Retourner objet Feedback pour compatibilitÃ©
        return Feedback(
            message_id=str(message_id),
            conversation_id=conversation_id,
            feedback_type=feedback_type,
            timestamp=feedback_db.created_at.isoformat(),
            query=query,
            response=response,
            tools_used=tools_used,
            corrected_response=corrected_response,
            reason=reason,
        )

    def get_feedback_stats(
        self, db: Session, user_id: Optional[str] = None, hours: int = 24
    ) -> Dict[str, Any]:
        """
        Retourne les statistiques de feedback depuis la DB.

        Args:
            db: Session base de donnÃ©es
            user_id: Filtrer par utilisateur (optionnel)
            hours: PÃ©riode en heures

        Returns:
            Statistiques dÃ©taillÃ©es
        """
        cutoff = datetime.now(timezone.utc) - timedelta(hours=hours)

        query = db.query(FeedbackModel)

        if user_id:
            query = query.filter(FeedbackModel.user_id == user_id)

        # Filtrer par pÃ©riode
        query = query.filter(FeedbackModel.created_at >= cutoff)

        feedbacks = query.all()

        # Calculer stats
        total = len(feedbacks)
        positive = len([f for f in feedbacks if f.feedback_type == "positive"])
        negative = len([f for f in feedbacks if f.feedback_type == "negative"])
        corrections = len([f for f in feedbacks if f.feedback_type == "correction"])

        return {
            "total": total,
            "positive": positive,
            "negative": negative,
            "corrections": corrections,
            "period_hours": hours,
            "positive_rate": positive / total if total > 0 else 0,
            "negative_rate": negative / total if total > 0 else 0,
        }

    def get_feedback_for_message(self, db: Session, message_id: int) -> List[FeedbackModel]:
        """RÃ©cupÃ¨re tous les feedbacks pour un message depuis la DB."""
        return db.query(FeedbackModel).filter(FeedbackModel.message_id == message_id).all()

    def get_corrections_for_training(self, db: Session, limit: int = 100) -> List[Dict[str, Any]]:
        """
        RÃ©cupÃ¨re les corrections pour le fine-tuning depuis la DB.

        Args:
            db: Session base de donnÃ©es
            limit: Nombre maximum de corrections

        Returns:
            Liste de paires (mauvaise rÃ©ponse, correction)
        """
        corrections_db = (
            db.query(FeedbackModel)
            .filter(
                FeedbackModel.feedback_type == "correction",
                FeedbackModel.corrected_response.isnot(None),
            )
            .order_by(FeedbackModel.created_at.desc())
            .limit(limit)
            .all()
        )

        corrections = []
        for f in corrections_db:
            tools = json.loads(f.tools_used) if f.tools_used else []
            corrections.append(
                {
                    "query": f.query,
                    "bad_response": f.response,
                    "good_response": f.corrected_response,
                    "tools_used": tools,
                    "timestamp": f.created_at.isoformat(),
                }
            )

        return corrections

    def export_for_finetuning(self, db: Session, format: str = "jsonl") -> str:
        """
        Exporte les donnÃ©es pour fine-tuning depuis la DB.

        Args:
            db: Session base de donnÃ©es
            format: Format d'export (jsonl, json)

        Returns:
            DonnÃ©es exportÃ©es en string
        """
        # Collecter les donnÃ©es positives et corrections
        training_data = []

        # Feedbacks positifs = bons exemples
        positive_feedbacks = (
            db.query(FeedbackModel).filter(FeedbackModel.feedback_type == "positive").all()
        )

        for f in positive_feedbacks:
            training_data.append(
                {
                    "messages": [
                        {"role": "user", "content": f.query},
                        {"role": "assistant", "content": f.response},
                    ],
                    "source": "positive_feedback",
                }
            )

        # Corrections = meilleurs exemples
        corrections = (
            db.query(FeedbackModel)
            .filter(
                FeedbackModel.feedback_type == "correction",
                FeedbackModel.corrected_response.isnot(None),
            )
            .all()
        )

        for f in corrections:
            training_data.append(
                {
                    "messages": [
                        {"role": "user", "content": f.query},
                        {"role": "assistant", "content": f.corrected_response},
                    ],
                    "source": "user_correction",
                }
            )

        if format == "jsonl":
            return "\n".join(json.dumps(d) for d in training_data)
        else:
            return json.dumps(training_data, indent=2)

    def get_improvement_priorities(self, db: Session) -> List[Dict[str, Any]]:
        """
        Identifie les prioritÃ©s d'amÃ©lioration depuis la DB.

        Args:
            db: Session base de donnÃ©es

        Returns:
            Liste triÃ©e des prioritÃ©s
        """
        priorities = []

        # Analyser les feedbacks nÃ©gatifs et corrections rÃ©cents
        recent_negative = (
            db.query(FeedbackModel)
            .filter(
                FeedbackModel.feedback_type.in_(["negative", "correction"]),
                FeedbackModel.created_at >= datetime.now(timezone.utc) - timedelta(days=7),
            )
            .all()
        )

        # Grouper par outils utilisÃ©s
        tool_failures = {}
        for f in recent_negative:
            if f.tools_used:
                tools = json.loads(f.tools_used)
                for tool in tools:
                    tool_name = tool.get("name") if isinstance(tool, dict) else tool
                    tool_failures[tool_name] = tool_failures.get(tool_name, 0) + 1

        # Ajouter aux prioritÃ©s
        for tool, count in sorted(tool_failures.items(), key=lambda x: x[1], reverse=True)[:5]:
            if count >= 2:
                priorities.append(
                    {
                        "type": "tool",
                        "priority": "high" if count >= 5 else "medium",
                        "description": f"Outil problÃ©matique: {tool}",
                        "failure_count": count,
                        "action": "VÃ©rifier la configuration et l'utilisation de cet outil",
                    }
                )

        return priorities


# Instance singleton
_feedback_collector: Optional[FeedbackCollector] = None


def get_feedback_collector() -> FeedbackCollector:
    """Retourne l'instance singleton."""
    global _feedback_collector
    if _feedback_collector is None:
        _feedback_collector = FeedbackCollector()
    return _feedback_collector
