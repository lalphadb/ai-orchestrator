# AI Orchestrator Backend v7.0 - Configuration Template
APP_VERSION=7.0
APP_NAME=AI Orchestrator

# Ollama (local LLM server)
OLLAMA_URL=http://localhost:11434
OLLAMA_BASE_URL=http://localhost:11434

# Modèles - Options: groq/llama-3.3-70b-versatile, ollama/kimi-k2:1t-cloud, etc.
DEFAULT_MODEL=groq/llama-3.3-70b-versatile
EXECUTOR_MODEL=groq/llama-3.3-70b-versatile

# API Keys (REQUIRED if using Groq)
# Get your key from: https://console.groq.com/keys
GROQ_API_KEY=your_groq_api_key_here

# Sécurité (CHANGE THESE IN PRODUCTION!)
# Generate JWT secret: python3 -c "import secrets; print(secrets.token_urlsafe(32))"
JWT_SECRET_KEY=change_this_to_random_64_char_string_in_production
ADMIN_PASSWORD=change_this_secure_admin_password

# Base de données
DATABASE_URL=sqlite:///./ai_orchestrator.db

# Workflow
VERIFY_REQUIRED=false
MAX_REPAIR_CYCLES=2
MAX_ITERATIONS=10

# EXECUTION MODE
# Options: direct (host execution), sandbox (Docker isolation)
EXECUTE_MODE=sandbox

# ChromaDB (vector database for learning)
CHROMA_HOST=localhost
CHROMA_PORT=8000

# Rate Limiting
RATE_LIMIT_PER_MINUTE=30
RATE_LIMIT_BURST=10

# CORS Origins (comma-separated)
# Production: use your actual domain
CORS_ORIGINS=http://localhost:3000,http://localhost:8001,http://10.10.10.46:8002
